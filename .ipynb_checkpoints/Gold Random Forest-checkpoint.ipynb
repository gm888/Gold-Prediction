{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "URL_VIX = 'https://za.investing.com/indices/volatility-s-p-500-historical-data?end_date=1596617279&st_date=1278367200'\n",
    "URL_GOLD = 'https://za.investing.com/commodities/gold-historical-data?end_date=1596551414&st_date=1280268000'\n",
    "URL_SILVER = 'https://za.investing.com/commodities/silver-historical-data?end_date=1596551414&st_date=1280268000'\n",
    "URL_USD_EUR = 'https://za.investing.com/currencies/eur-usd-historical-data?end_date=1596551414&st_date=1280268000'\n",
    "URL_USD_CNY = 'https://za.investing.com/currencies/usd-cny-historical-data?end_date=1596551414&st_date=1280268000'\n",
    "\n",
    "headers = {'User-Agent': \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36\"}\n",
    "\n",
    "df = DataFrame()\n",
    "\n",
    "def extract_data(URL):\n",
    "    \n",
    "    page = requests.get(URL, headers = headers).text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    table = soup.find(\"table\", attrs={\"class\": \"common-table medium js-table\"})\n",
    "\n",
    "    prices_table_data_rows = table.tbody.find_all(\"tr\")  # contains 2 rows\n",
    "    data = {}\n",
    "    t_headers = []\n",
    "    for th in table.find_all(\"th\"):\n",
    "        t_headers.append(th.text.replace('\\n', ' ').strip())\n",
    "\n",
    "\n",
    "    table_data = []\n",
    "    for tr in table.tbody.find_all(\"tr\"): # find all tr's from table's tbody\n",
    "        t_row = {}\n",
    "\n",
    "        for td, th in zip(tr.find_all(\"td\"), t_headers): \n",
    "            t_row[th] = td.text.replace('\\n', '').strip()\n",
    "        table_data.append(t_row)\n",
    "    return table_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = DataFrame(extract_data(URL_VIX))\n",
    "df['Index'] = 'VIX'\n",
    "df1 = DataFrame(extract_data(URL_GOLD))\n",
    "df1['Index'] = 'GOLD'\n",
    "df2 = DataFrame(extract_data(URL_SILVER))\n",
    "df2['Index'] = 'SILVER'\n",
    "df3 = DataFrame(extract_data(URL_USD_EUR))\n",
    "df3['Index'] = 'USD_EUR'\n",
    "df4 = DataFrame(extract_data(URL_USD_CNY))\n",
    "df4['Index'] = 'USD_CNY'\n",
    "\n",
    "\n",
    "frames = [df,df1,df2,df3,df4]\n",
    "result = pd.concat(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cpi(URL):\n",
    "    page = requests.get(URL, headers = headers).text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    table = soup.find(\"table\", attrs={\"class\": \"regular\"})\n",
    "\n",
    "    prices_table_data_rows = table.tbody.find_all(\"tr\")  \n",
    "    data = {}\n",
    "    t_headers = []\n",
    "    for th in table.find_all(\"th\"):\n",
    "        t_headers.append(th.text.replace('\\n', ' ').strip())\n",
    "\n",
    "\n",
    "    table_data = []\n",
    "    for tr in table.tbody.find_all(\"tr\"): \n",
    "        t_row = {}\n",
    "        \n",
    "      \n",
    "        for td, th in zip(tr.find_all(\"td\"), t_headers): \n",
    "            t_row[th] = td.text.replace('\\n', '').strip()\n",
    "            \n",
    "        table_data.append(t_row)\n",
    "\n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi_df = extract_cpi('https://www.bls.gov/regions/mid-atlantic/data/consumerpriceindexhistorical_us_table.htm')\n",
    "\n",
    "cpi_df = DataFrame(cpi_df)\n",
    "cpi_df = cpi_df.set_axis(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'], axis=1, inplace=False)\n",
    "cpi_df=cpi_df[:12]\n",
    "cpi_df=cpi_df.drop(cpi_df.index[0])\n",
    "year = ['2010','2011','2012','2013','2014','2015','2016','2017','2018','2019','2020']\n",
    "cpi_df.insert(0, 'Year', year)\n",
    "\n",
    "cpi_final_df = pd.melt(cpi_df, id_vars=['Year'], var_name='Date', value_name='Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Date'] = pd.to_datetime(result['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Price'] = result['Price'].str.replace(',','')\n",
    "result['Price'] = pd.to_numeric(result['Price'])\n",
    "\n",
    "result['Open'] = result['Open'].str.replace(',','')\n",
    "result['Open'] = pd.to_numeric(result['Open'])\n",
    "\n",
    "result['High'] = result['High'].str.replace(',','')\n",
    "result['High'] = pd.to_numeric(result['High'])\n",
    "\n",
    "result['Low'] = result['Low'].str.replace(',','')\n",
    "result['Low'] = pd.to_numeric(result['Low'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Mid'] = (result['High']+ result['Low'])/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_df = pd.read_excel('M2.xls')\n",
    "m2_df = m2_df.rename({'m2': 'Mid'}, axis=1) \n",
    "m2_df['Index'] = 'M2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df=pd.merge(result, m2_df[['Date','Mid','Index']],on='Date', how='left')\n",
    "\n",
    "frames1 = [result, m2_df]\n",
    "final_frame=pd.concat(frames1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_frame.groupby(['Date', 'Index'], as_index=False)['Mid'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['Date'] < '2010-07-28'].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Mid'].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result.drop(['Date','High','Low','Open','Volume','Chg%','Mid','Volume'],1,inplace =True)\n",
    "table = df.pivot(index='Date', columns='Index', values='Mid')\n",
    "\n",
    "df_corr = table.corr()\n",
    "print(df_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr['GOLD'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x =table['VIX'], y = table['GOLD'], kind='hex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6,5))\n",
    "sns.heatmap(df_corr,\n",
    "            xticklabels=df_corr.columns.values,\n",
    "            yticklabels=df_corr.columns.values,\n",
    "            annot=True,fmt='.2f',linewidths=0.30)\n",
    "plt.title('Correlation of Features', y = 1.05, size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table['M2'] = table['M2'].fillna(method='bfill')\n",
    "table['SILVER'] = table['SILVER'].fillna(method='bfill')\n",
    "table['USD_CNY'] = table['USD_CNY'].fillna(method='bfill')\n",
    "table['USD_EUR'] = table['USD_EUR'].fillna(method='bfill')\n",
    "table['VIX'] = table['VIX'].fillna(method='bfill')\n",
    "table['GOLD'] = table['GOLD'].fillna(method='bfill')\n",
    "\n",
    "table['M2'] = table['M2'].fillna(method='ffill')\n",
    "table['SILVER'] = table['SILVER'].fillna(method='ffill')\n",
    "table['USD_CNY'] = table['USD_CNY'].fillna(method='ffill')\n",
    "table['USD_EUR'] = table['USD_EUR'].fillna(method='ffill')\n",
    "table['VIX'] =table['VIX'].fillna(method='ffill')\n",
    "table['GOLD'] = table['GOLD'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = table[['SILVER','M2','USD_CNY','USD_EUR','VIX']] \n",
    "\n",
    "y = table['GOLD']   # mentioning response variable\n",
    "#splitting the train and test dataset\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=101)  #splitting train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9ab415169af1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mregressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE :   55.07492345216484\n",
      "MSE :   5739.273127703049\n",
      "RMAE :   75.75799052049261\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "print('MAE :',\" \", metrics.mean_absolute_error(y_test,predictions))\n",
    "print('MSE :',\" \", metrics.mean_squared_error(y_test,predictions))\n",
    "print('RMAE :',\" \", np.sqrt(metrics.mean_squared_error(y_test,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8080150306497997"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score = metrics.r2_score(y_test,predictions)\n",
    "r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE :   55.07492345216484\n",
      "MSE :   5739.273127703049\n",
      "RMAE :   75.75799052049261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8080150306497997"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'n_neighbors':[2,3,4,5,6,7,8,9]}\n",
    "\n",
    "knn = neighbors.KNeighborsRegressor()\n",
    "knn_model = GridSearchCV(knn, params, cv=5)\n",
    "\n",
    "knn_model.fit(X_train,y_train)\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "\n",
    "print('MAE :',\" \", metrics.mean_absolute_error(y_test,predictions))\n",
    "print('MSE :',\" \", metrics.mean_squared_error(y_test,predictions))\n",
    "print('RMAE :',\" \", np.sqrt(metrics.mean_squared_error(y_test,predictions)))\n",
    "r2_score = metrics.r2_score(y_test,predictions)\n",
    "r2_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
